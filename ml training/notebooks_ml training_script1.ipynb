{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import sklearn\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nX = preprocessing.StandardScaler().fit(X).transform(X)\n\nimport numpy as np\nimport pandas as pd",
      "metadata": {
        "trusted": true
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#data = load_breast_cancer()\n#print (data.feature_names)\ndf = pd.read_csv('.//ml training//data.csv')\n\n#data.feature_names\ndf.shape",
      "metadata": {
        "trusted": true
      },
      "execution_count": 162,
      "outputs": [
        {
          "execution_count": 162,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(569, 33)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "df.tail(16)\n#df.head()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 166,
      "outputs": [
        {
          "execution_count": 166,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n553  924342         B        9.333         21.94           59.01      264.0   \n554  924632         B       12.880         28.92           82.50      514.3   \n555  924934         B       10.290         27.61           65.67      321.4   \n556  924964         B       10.160         19.59           64.73      311.7   \n557  925236         B        9.423         27.88           59.26      271.3   \n558  925277         B       14.590         22.68           96.39      657.1   \n559  925291         B       11.510         23.93           74.52      403.5   \n560  925292         B       14.050         27.15           91.38      600.4   \n561  925311         B       11.200         29.37           70.67      386.0   \n562  925622         M       15.220         30.62          103.40      716.9   \n563  926125         M       20.920         25.09          143.00     1347.0   \n564  926424         M       21.560         22.39          142.00     1479.0   \n565  926682         M       20.130         28.25          131.20     1261.0   \n566  926954         M       16.600         28.08          108.30      858.1   \n567  927241         M       20.600         29.33          140.10     1265.0   \n568   92751         B        7.760         24.54           47.92      181.0   \n\n     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n553          0.09240           0.05605        0.039960              0.01282   \n554          0.08123           0.05824        0.061950              0.02343   \n555          0.09030           0.07658        0.059990              0.02738   \n556          0.10030           0.07504        0.005025              0.01116   \n557          0.08123           0.04971        0.000000              0.00000   \n558          0.08473           0.13300        0.102900              0.03736   \n559          0.09261           0.10210        0.111200              0.04105   \n560          0.09929           0.11260        0.044620              0.04304   \n561          0.07449           0.03558        0.000000              0.00000   \n562          0.10480           0.20870        0.255000              0.09429   \n563          0.10990           0.22360        0.317400              0.14740   \n564          0.11100           0.11590        0.243900              0.13890   \n565          0.09780           0.10340        0.144000              0.09791   \n566          0.08455           0.10230        0.092510              0.05302   \n567          0.11780           0.27700        0.351400              0.15200   \n568          0.05263           0.04362        0.000000              0.00000   \n\n     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n553  ...          25.05            62.86       295.8           0.11030   \n554  ...          35.74            88.84       595.7           0.12270   \n555  ...          34.91            69.57       357.6           0.13840   \n556  ...          22.88            67.88       347.3           0.12650   \n557  ...          34.24            66.50       330.6           0.10730   \n558  ...          27.27           105.90       733.5           0.10260   \n559  ...          37.16            82.28       474.2           0.12980   \n560  ...          33.17           100.20       706.7           0.12410   \n561  ...          38.30            75.19       439.6           0.09267   \n562  ...          42.79           128.70       915.0           0.14170   \n563  ...          29.41           179.10      1819.0           0.14070   \n564  ...          26.40           166.10      2027.0           0.14100   \n565  ...          38.25           155.00      1731.0           0.11660   \n566  ...          34.12           126.70      1124.0           0.11390   \n567  ...          39.42           184.60      1821.0           0.16500   \n568  ...          30.37            59.16       268.6           0.08996   \n\n     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n553            0.08298          0.07993               0.02564          0.2435   \n554            0.16200          0.24390               0.06493          0.2372   \n555            0.17100          0.20000               0.09127          0.2226   \n556            0.12000          0.01005               0.02232          0.2262   \n557            0.07158          0.00000               0.00000          0.2475   \n558            0.31710          0.36620               0.11050          0.2258   \n559            0.25170          0.36300               0.09653          0.2112   \n560            0.22640          0.13260               0.10480          0.2250   \n561            0.05494          0.00000               0.00000          0.1566   \n562            0.79170          1.17000               0.23560          0.4089   \n563            0.41860          0.65990               0.25420          0.2929   \n564            0.21130          0.41070               0.22160          0.2060   \n565            0.19220          0.32150               0.16280          0.2572   \n566            0.30940          0.34030               0.14180          0.2218   \n567            0.86810          0.93870               0.26500          0.4087   \n568            0.06444          0.00000               0.00000          0.2871   \n\n     fractal_dimension_worst  Unnamed: 32  \n553                  0.07393          NaN  \n554                  0.07242          NaN  \n555                  0.08283          NaN  \n556                  0.06742          NaN  \n557                  0.06969          NaN  \n558                  0.08004          NaN  \n559                  0.08732          NaN  \n560                  0.08321          NaN  \n561                  0.05905          NaN  \n562                  0.14090          NaN  \n563                  0.09873          NaN  \n564                  0.07115          NaN  \n565                  0.06637          NaN  \n566                  0.07820          NaN  \n567                  0.12400          NaN  \n568                  0.07039          NaN  \n\n[16 rows x 33 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>553</th>\n      <td>924342</td>\n      <td>B</td>\n      <td>9.333</td>\n      <td>21.94</td>\n      <td>59.01</td>\n      <td>264.0</td>\n      <td>0.09240</td>\n      <td>0.05605</td>\n      <td>0.039960</td>\n      <td>0.01282</td>\n      <td>...</td>\n      <td>25.05</td>\n      <td>62.86</td>\n      <td>295.8</td>\n      <td>0.11030</td>\n      <td>0.08298</td>\n      <td>0.07993</td>\n      <td>0.02564</td>\n      <td>0.2435</td>\n      <td>0.07393</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>554</th>\n      <td>924632</td>\n      <td>B</td>\n      <td>12.880</td>\n      <td>28.92</td>\n      <td>82.50</td>\n      <td>514.3</td>\n      <td>0.08123</td>\n      <td>0.05824</td>\n      <td>0.061950</td>\n      <td>0.02343</td>\n      <td>...</td>\n      <td>35.74</td>\n      <td>88.84</td>\n      <td>595.7</td>\n      <td>0.12270</td>\n      <td>0.16200</td>\n      <td>0.24390</td>\n      <td>0.06493</td>\n      <td>0.2372</td>\n      <td>0.07242</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>555</th>\n      <td>924934</td>\n      <td>B</td>\n      <td>10.290</td>\n      <td>27.61</td>\n      <td>65.67</td>\n      <td>321.4</td>\n      <td>0.09030</td>\n      <td>0.07658</td>\n      <td>0.059990</td>\n      <td>0.02738</td>\n      <td>...</td>\n      <td>34.91</td>\n      <td>69.57</td>\n      <td>357.6</td>\n      <td>0.13840</td>\n      <td>0.17100</td>\n      <td>0.20000</td>\n      <td>0.09127</td>\n      <td>0.2226</td>\n      <td>0.08283</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>556</th>\n      <td>924964</td>\n      <td>B</td>\n      <td>10.160</td>\n      <td>19.59</td>\n      <td>64.73</td>\n      <td>311.7</td>\n      <td>0.10030</td>\n      <td>0.07504</td>\n      <td>0.005025</td>\n      <td>0.01116</td>\n      <td>...</td>\n      <td>22.88</td>\n      <td>67.88</td>\n      <td>347.3</td>\n      <td>0.12650</td>\n      <td>0.12000</td>\n      <td>0.01005</td>\n      <td>0.02232</td>\n      <td>0.2262</td>\n      <td>0.06742</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>557</th>\n      <td>925236</td>\n      <td>B</td>\n      <td>9.423</td>\n      <td>27.88</td>\n      <td>59.26</td>\n      <td>271.3</td>\n      <td>0.08123</td>\n      <td>0.04971</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>34.24</td>\n      <td>66.50</td>\n      <td>330.6</td>\n      <td>0.10730</td>\n      <td>0.07158</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.2475</td>\n      <td>0.06969</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>558</th>\n      <td>925277</td>\n      <td>B</td>\n      <td>14.590</td>\n      <td>22.68</td>\n      <td>96.39</td>\n      <td>657.1</td>\n      <td>0.08473</td>\n      <td>0.13300</td>\n      <td>0.102900</td>\n      <td>0.03736</td>\n      <td>...</td>\n      <td>27.27</td>\n      <td>105.90</td>\n      <td>733.5</td>\n      <td>0.10260</td>\n      <td>0.31710</td>\n      <td>0.36620</td>\n      <td>0.11050</td>\n      <td>0.2258</td>\n      <td>0.08004</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>559</th>\n      <td>925291</td>\n      <td>B</td>\n      <td>11.510</td>\n      <td>23.93</td>\n      <td>74.52</td>\n      <td>403.5</td>\n      <td>0.09261</td>\n      <td>0.10210</td>\n      <td>0.111200</td>\n      <td>0.04105</td>\n      <td>...</td>\n      <td>37.16</td>\n      <td>82.28</td>\n      <td>474.2</td>\n      <td>0.12980</td>\n      <td>0.25170</td>\n      <td>0.36300</td>\n      <td>0.09653</td>\n      <td>0.2112</td>\n      <td>0.08732</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>560</th>\n      <td>925292</td>\n      <td>B</td>\n      <td>14.050</td>\n      <td>27.15</td>\n      <td>91.38</td>\n      <td>600.4</td>\n      <td>0.09929</td>\n      <td>0.11260</td>\n      <td>0.044620</td>\n      <td>0.04304</td>\n      <td>...</td>\n      <td>33.17</td>\n      <td>100.20</td>\n      <td>706.7</td>\n      <td>0.12410</td>\n      <td>0.22640</td>\n      <td>0.13260</td>\n      <td>0.10480</td>\n      <td>0.2250</td>\n      <td>0.08321</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>561</th>\n      <td>925311</td>\n      <td>B</td>\n      <td>11.200</td>\n      <td>29.37</td>\n      <td>70.67</td>\n      <td>386.0</td>\n      <td>0.07449</td>\n      <td>0.03558</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>38.30</td>\n      <td>75.19</td>\n      <td>439.6</td>\n      <td>0.09267</td>\n      <td>0.05494</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.1566</td>\n      <td>0.05905</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>562</th>\n      <td>925622</td>\n      <td>M</td>\n      <td>15.220</td>\n      <td>30.62</td>\n      <td>103.40</td>\n      <td>716.9</td>\n      <td>0.10480</td>\n      <td>0.20870</td>\n      <td>0.255000</td>\n      <td>0.09429</td>\n      <td>...</td>\n      <td>42.79</td>\n      <td>128.70</td>\n      <td>915.0</td>\n      <td>0.14170</td>\n      <td>0.79170</td>\n      <td>1.17000</td>\n      <td>0.23560</td>\n      <td>0.4089</td>\n      <td>0.14090</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>563</th>\n      <td>926125</td>\n      <td>M</td>\n      <td>20.920</td>\n      <td>25.09</td>\n      <td>143.00</td>\n      <td>1347.0</td>\n      <td>0.10990</td>\n      <td>0.22360</td>\n      <td>0.317400</td>\n      <td>0.14740</td>\n      <td>...</td>\n      <td>29.41</td>\n      <td>179.10</td>\n      <td>1819.0</td>\n      <td>0.14070</td>\n      <td>0.41860</td>\n      <td>0.65990</td>\n      <td>0.25420</td>\n      <td>0.2929</td>\n      <td>0.09873</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>926424</td>\n      <td>M</td>\n      <td>21.560</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.243900</td>\n      <td>0.13890</td>\n      <td>...</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.41070</td>\n      <td>0.22160</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>926682</td>\n      <td>M</td>\n      <td>20.130</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.144000</td>\n      <td>0.09791</td>\n      <td>...</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.32150</td>\n      <td>0.16280</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>926954</td>\n      <td>M</td>\n      <td>16.600</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.092510</td>\n      <td>0.05302</td>\n      <td>...</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.34030</td>\n      <td>0.14180</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>927241</td>\n      <td>M</td>\n      <td>20.600</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.351400</td>\n      <td>0.15200</td>\n      <td>...</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.93870</td>\n      <td>0.26500</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>92751</td>\n      <td>B</td>\n      <td>7.760</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>16 rows × 33 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "df.iloc[26:27]",
      "metadata": {
        "trusted": true
      },
      "execution_count": 156,
      "outputs": [
        {
          "execution_count": 156,
          "output_type": "execute_result",
          "data": {
            "text/plain": "        id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n26  852763         M        14.58         21.53           97.41      644.8   \n\n    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n26           0.1054            0.1868          0.1425              0.08783   \n\n    ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n26  ...          33.21            122.4       896.9            0.1525   \n\n    compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n26             0.6643           0.5539                0.2701          0.4264   \n\n    fractal_dimension_worst  Unnamed: 32  \n26                   0.1275          NaN  \n\n[1 rows x 33 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26</th>\n      <td>852763</td>\n      <td>M</td>\n      <td>14.58</td>\n      <td>21.53</td>\n      <td>97.41</td>\n      <td>644.8</td>\n      <td>0.1054</td>\n      <td>0.1868</td>\n      <td>0.1425</td>\n      <td>0.08783</td>\n      <td>...</td>\n      <td>33.21</td>\n      <td>122.4</td>\n      <td>896.9</td>\n      <td>0.1525</td>\n      <td>0.6643</td>\n      <td>0.5539</td>\n      <td>0.2701</td>\n      <td>0.4264</td>\n      <td>0.1275</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 33 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#X = data.data\n#y = data.target\n#df.head()\n#print(df.columns)\n\nX = df.iloc[:, 2:-1]\ny = df['diagnosis'].apply(lambda x: 1 if x == 'M' else 0)",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#df = pd.DataFrame(data)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\nX_train",
      "metadata": {
        "trusted": true
      },
      "execution_count": 112,
      "outputs": [
        {
          "execution_count": 112,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n226       10.440         15.46           66.62      329.6          0.10530   \n333       11.250         14.78           71.38      390.0          0.08306   \n451       19.590         25.00          127.70     1191.0          0.10320   \n266       10.600         18.95           69.28      346.4          0.09688   \n523       13.710         18.68           88.73      571.0          0.09916   \n..           ...           ...             ...        ...              ...   \n295       13.770         13.27           88.06      582.7          0.09198   \n254       19.450         19.33          126.50     1169.0          0.10350   \n234        9.567         15.91           60.21      279.6          0.08464   \n273        9.742         15.67           61.50      289.9          0.09037   \n323       20.340         21.51          135.90     1264.0          0.11700   \n\n     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n226           0.07722        0.006643             0.012160         0.1788   \n333           0.04458        0.000974             0.002941         0.1773   \n451           0.09871        0.165500             0.090630         0.1663   \n266           0.11470        0.063870             0.026420         0.1922   \n523           0.10700        0.053850             0.037830         0.1714   \n..                ...             ...                  ...            ...   \n295           0.06221        0.010630             0.019170         0.1592   \n254           0.11880        0.137900             0.085910         0.1776   \n234           0.04087        0.016520             0.016670         0.1551   \n273           0.04689        0.011030             0.014070         0.2081   \n323           0.18750        0.256500             0.150400         0.2569   \n\n     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n226                 0.06450  ...         11.52          19.80   \n333                 0.06081  ...         12.76          22.06   \n451                 0.05391  ...         21.44          30.96   \n266                 0.06491  ...         11.88          22.94   \n523                 0.06843  ...         15.11          25.63   \n..                      ...  ...           ...            ...   \n295                 0.05912  ...         14.67          16.93   \n254                 0.05647  ...         25.70          24.57   \n234                 0.06403  ...         10.51          19.16   \n273                 0.06312  ...         10.75          20.88   \n323                 0.06670  ...         25.30          31.86   \n\n     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n226            73.47       395.4            0.1341            0.11530   \n333            82.08       492.7            0.1166            0.09794   \n451           139.80      1421.0            0.1528            0.18450   \n266            78.28       424.8            0.1213            0.25150   \n523            99.43       701.9            0.1425            0.25660   \n..               ...         ...               ...                ...   \n295            94.17       661.1            0.1170            0.10720   \n254           163.10      1972.0            0.1497            0.31610   \n234            65.74       335.9            0.1504            0.09515   \n273            68.09       355.2            0.1467            0.09370   \n323           171.10      1938.0            0.1592            0.44920   \n\n     concavity_worst  concave points_worst  symmetry_worst  \\\n226         0.026390               0.04464          0.2615   \n333         0.005518               0.01667          0.2815   \n451         0.397700               0.14660          0.2293   \n266         0.191600               0.07926          0.2940   \n523         0.193500               0.12840          0.2849   \n..               ...                   ...             ...   \n295         0.037320               0.05802          0.2823   \n254         0.431700               0.19990          0.3379   \n234         0.071610               0.07222          0.2757   \n273         0.040430               0.05159          0.2841   \n323         0.534400               0.26850          0.5558   \n\n     fractal_dimension_worst  \n226                  0.08269  \n333                  0.07418  \n451                  0.06091  \n266                  0.07587  \n523                  0.09031  \n..                       ...  \n295                  0.06794  \n254                  0.08950  \n234                  0.08178  \n273                  0.08175  \n323                  0.10240  \n\n[381 rows x 30 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>226</th>\n      <td>10.440</td>\n      <td>15.46</td>\n      <td>66.62</td>\n      <td>329.6</td>\n      <td>0.10530</td>\n      <td>0.07722</td>\n      <td>0.006643</td>\n      <td>0.012160</td>\n      <td>0.1788</td>\n      <td>0.06450</td>\n      <td>...</td>\n      <td>11.52</td>\n      <td>19.80</td>\n      <td>73.47</td>\n      <td>395.4</td>\n      <td>0.1341</td>\n      <td>0.11530</td>\n      <td>0.026390</td>\n      <td>0.04464</td>\n      <td>0.2615</td>\n      <td>0.08269</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>11.250</td>\n      <td>14.78</td>\n      <td>71.38</td>\n      <td>390.0</td>\n      <td>0.08306</td>\n      <td>0.04458</td>\n      <td>0.000974</td>\n      <td>0.002941</td>\n      <td>0.1773</td>\n      <td>0.06081</td>\n      <td>...</td>\n      <td>12.76</td>\n      <td>22.06</td>\n      <td>82.08</td>\n      <td>492.7</td>\n      <td>0.1166</td>\n      <td>0.09794</td>\n      <td>0.005518</td>\n      <td>0.01667</td>\n      <td>0.2815</td>\n      <td>0.07418</td>\n    </tr>\n    <tr>\n      <th>451</th>\n      <td>19.590</td>\n      <td>25.00</td>\n      <td>127.70</td>\n      <td>1191.0</td>\n      <td>0.10320</td>\n      <td>0.09871</td>\n      <td>0.165500</td>\n      <td>0.090630</td>\n      <td>0.1663</td>\n      <td>0.05391</td>\n      <td>...</td>\n      <td>21.44</td>\n      <td>30.96</td>\n      <td>139.80</td>\n      <td>1421.0</td>\n      <td>0.1528</td>\n      <td>0.18450</td>\n      <td>0.397700</td>\n      <td>0.14660</td>\n      <td>0.2293</td>\n      <td>0.06091</td>\n    </tr>\n    <tr>\n      <th>266</th>\n      <td>10.600</td>\n      <td>18.95</td>\n      <td>69.28</td>\n      <td>346.4</td>\n      <td>0.09688</td>\n      <td>0.11470</td>\n      <td>0.063870</td>\n      <td>0.026420</td>\n      <td>0.1922</td>\n      <td>0.06491</td>\n      <td>...</td>\n      <td>11.88</td>\n      <td>22.94</td>\n      <td>78.28</td>\n      <td>424.8</td>\n      <td>0.1213</td>\n      <td>0.25150</td>\n      <td>0.191600</td>\n      <td>0.07926</td>\n      <td>0.2940</td>\n      <td>0.07587</td>\n    </tr>\n    <tr>\n      <th>523</th>\n      <td>13.710</td>\n      <td>18.68</td>\n      <td>88.73</td>\n      <td>571.0</td>\n      <td>0.09916</td>\n      <td>0.10700</td>\n      <td>0.053850</td>\n      <td>0.037830</td>\n      <td>0.1714</td>\n      <td>0.06843</td>\n      <td>...</td>\n      <td>15.11</td>\n      <td>25.63</td>\n      <td>99.43</td>\n      <td>701.9</td>\n      <td>0.1425</td>\n      <td>0.25660</td>\n      <td>0.193500</td>\n      <td>0.12840</td>\n      <td>0.2849</td>\n      <td>0.09031</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>13.770</td>\n      <td>13.27</td>\n      <td>88.06</td>\n      <td>582.7</td>\n      <td>0.09198</td>\n      <td>0.06221</td>\n      <td>0.010630</td>\n      <td>0.019170</td>\n      <td>0.1592</td>\n      <td>0.05912</td>\n      <td>...</td>\n      <td>14.67</td>\n      <td>16.93</td>\n      <td>94.17</td>\n      <td>661.1</td>\n      <td>0.1170</td>\n      <td>0.10720</td>\n      <td>0.037320</td>\n      <td>0.05802</td>\n      <td>0.2823</td>\n      <td>0.06794</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>19.450</td>\n      <td>19.33</td>\n      <td>126.50</td>\n      <td>1169.0</td>\n      <td>0.10350</td>\n      <td>0.11880</td>\n      <td>0.137900</td>\n      <td>0.085910</td>\n      <td>0.1776</td>\n      <td>0.05647</td>\n      <td>...</td>\n      <td>25.70</td>\n      <td>24.57</td>\n      <td>163.10</td>\n      <td>1972.0</td>\n      <td>0.1497</td>\n      <td>0.31610</td>\n      <td>0.431700</td>\n      <td>0.19990</td>\n      <td>0.3379</td>\n      <td>0.08950</td>\n    </tr>\n    <tr>\n      <th>234</th>\n      <td>9.567</td>\n      <td>15.91</td>\n      <td>60.21</td>\n      <td>279.6</td>\n      <td>0.08464</td>\n      <td>0.04087</td>\n      <td>0.016520</td>\n      <td>0.016670</td>\n      <td>0.1551</td>\n      <td>0.06403</td>\n      <td>...</td>\n      <td>10.51</td>\n      <td>19.16</td>\n      <td>65.74</td>\n      <td>335.9</td>\n      <td>0.1504</td>\n      <td>0.09515</td>\n      <td>0.071610</td>\n      <td>0.07222</td>\n      <td>0.2757</td>\n      <td>0.08178</td>\n    </tr>\n    <tr>\n      <th>273</th>\n      <td>9.742</td>\n      <td>15.67</td>\n      <td>61.50</td>\n      <td>289.9</td>\n      <td>0.09037</td>\n      <td>0.04689</td>\n      <td>0.011030</td>\n      <td>0.014070</td>\n      <td>0.2081</td>\n      <td>0.06312</td>\n      <td>...</td>\n      <td>10.75</td>\n      <td>20.88</td>\n      <td>68.09</td>\n      <td>355.2</td>\n      <td>0.1467</td>\n      <td>0.09370</td>\n      <td>0.040430</td>\n      <td>0.05159</td>\n      <td>0.2841</td>\n      <td>0.08175</td>\n    </tr>\n    <tr>\n      <th>323</th>\n      <td>20.340</td>\n      <td>21.51</td>\n      <td>135.90</td>\n      <td>1264.0</td>\n      <td>0.11700</td>\n      <td>0.18750</td>\n      <td>0.256500</td>\n      <td>0.150400</td>\n      <td>0.2569</td>\n      <td>0.06670</td>\n      <td>...</td>\n      <td>25.30</td>\n      <td>31.86</td>\n      <td>171.10</td>\n      <td>1938.0</td>\n      <td>0.1592</td>\n      <td>0.44920</td>\n      <td>0.534400</td>\n      <td>0.26850</td>\n      <td>0.5558</td>\n      <td>0.10240</td>\n    </tr>\n  </tbody>\n</table>\n<p>381 rows × 30 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "from sklearn import svm\nclf = svm.SVC(gamma=0.001, C=100.)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "clf.fit(X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 114,
      "outputs": [
        {
          "execution_count": 114,
          "output_type": "execute_result",
          "data": {
            "text/plain": "SVC(C=100.0, gamma=0.001)",
            "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100.0, gamma=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100.0, gamma=0.001)</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "y_pred = clf.predict(X_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\nconf_matrix = confusion_matrix(y_test, y_pred)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import pickle\ns = pickle.dumps(clf)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "%pip install seaborn",
      "metadata": {
        "trusted": true
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import seaborn as sns\n\nlabels = [['True Neg','False Pos'],['False Neg','True Pos']]\ndf_cm = pd.DataFrame(conf_matrix)\nsns.set(font_scale=1)\nsns.heatmap(df_cm, annot=labels, fmt='', cmap='Blues')",
      "metadata": {
        "trusted": true
      },
      "execution_count": 119,
      "outputs": [
        {
          "execution_count": 119,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<AxesSubplot:>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 2 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#Test\nx_test = df.iloc[30, 2:-1]\nprint(X_test)\ny_test = y[30]\nprint(y_test)\n#print(y_test)\ny_p = clf.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 136,
      "outputs": [
        {
          "name": "stdout",
          "text": "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n66         9.465         21.01           60.11      269.4          0.10440   \n460       17.080         27.15          111.20      930.9          0.09898   \n102       12.180         20.52           77.22      458.7          0.08013   \n187       11.710         17.19           74.68      420.3          0.09774   \n229       12.830         22.33           85.26      503.2          0.10880   \n..           ...           ...             ...        ...              ...   \n257       15.320         17.27          103.20      713.3          0.13350   \n463       11.600         18.36           73.88      412.7          0.08508   \n444       18.030         16.85          117.50      990.0          0.08947   \n55        11.520         18.75           73.34      409.0          0.09524   \n26        14.580         21.53           97.41      644.8          0.10540   \n\n     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n66            0.07773         0.02172              0.01504         0.1717   \n460           0.11100         0.10070              0.06431         0.1793   \n102           0.04038         0.02383              0.01770         0.1739   \n187           0.06141         0.03809              0.03239         0.1516   \n229           0.17990         0.16950              0.06861         0.2123   \n..                ...             ...                  ...            ...   \n257           0.22840         0.24480              0.12420         0.2398   \n463           0.05855         0.03367              0.01777         0.1516   \n444           0.12320         0.10900              0.06254         0.1720   \n55            0.05473         0.03036              0.02278         0.1920   \n26            0.18680         0.14250              0.08783         0.2252   \n\n     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n66                  0.06899  ...         10.41          31.56   \n460                 0.06281  ...         22.96          34.49   \n102                 0.05677  ...         13.34          32.84   \n187                 0.06095  ...         13.01          21.39   \n229                 0.07254  ...         15.20          30.15   \n..                      ...  ...           ...            ...   \n257                 0.07596  ...         17.73          22.66   \n463                 0.05859  ...         12.77          24.02   \n444                 0.05780  ...         20.38          22.02   \n55                  0.05907  ...         12.84          22.47   \n26                  0.06924  ...         17.62          33.21   \n\n     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n66             67.03       330.7            0.1548            0.16640   \n460           152.10      1648.0            0.1600            0.24440   \n102            84.58       547.8            0.1123            0.08862   \n187            84.42       521.5            0.1323            0.10400   \n229           105.30       706.0            0.1777            0.53430   \n..               ...         ...               ...                ...   \n257           119.80       928.8            0.1765            0.45030   \n463            82.68       495.1            0.1342            0.18080   \n444           133.30      1292.0            0.1263            0.26660   \n55             81.81       506.2            0.1249            0.08720   \n26            122.40       896.9            0.1525            0.66430   \n\n     concavity_worst  concave points_worst  symmetry_worst  \\\n66           0.09412               0.06517          0.2878   \n460          0.26390               0.15550          0.3010   \n102          0.11450               0.07431          0.2694   \n187          0.15210               0.10990          0.2572   \n229          0.62820               0.19770          0.3407   \n..               ...                   ...             ...   \n257          0.44290               0.22290          0.3258   \n463          0.18600               0.08288          0.3210   \n444          0.42900               0.15350          0.2842   \n55           0.09076               0.06316          0.3306   \n26           0.55390               0.27010          0.4264   \n\n     fractal_dimension_worst  \n66                   0.09211  \n460                  0.09060  \n102                  0.06878  \n187                  0.07097  \n229                  0.12430  \n..                       ...  \n257                  0.11910  \n463                  0.07863  \n444                  0.08225  \n55                   0.07036  \n26                   0.12750  \n\n[188 rows x 30 columns]\n1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "ename": "<class 'ValueError'>",
          "evalue": "Expected 2D array, got 1D array instead:\narray=[1.863e+01 2.511e+01 1.248e+02 1.088e+03 1.064e-01 1.887e-01 2.319e-01\n 1.244e-01 2.183e-01 6.197e-02 8.307e-01 1.466e+00 5.574e+00 1.050e+02\n 6.248e-03 3.374e-02 5.196e-02 1.158e-02 2.007e-02 4.560e-03 2.315e+01\n 3.401e+01 1.605e+02 1.670e+03 1.491e-01 4.257e-01 6.133e-01 1.848e-01\n 3.444e-01 9.782e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[136], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_test)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#print(y_test)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m y_p \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/sklearn/svm/_base.py:820\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    818\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/sklearn/svm/_base.py:433\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/sklearn/svm/_base.py:613\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    610\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 613\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39misspmatrix(X):\n\u001b[1;32m    623\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 535\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    536\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
            "File \u001b[0;32m/lib/python3.10/site-packages/sklearn/utils/validation.py:900\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 900\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    901\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    902\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    905\u001b[0m         )\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1.863e+01 2.511e+01 1.248e+02 1.088e+03 1.064e-01 1.887e-01 2.319e-01\n 1.244e-01 2.183e-01 6.197e-02 8.307e-01 1.466e+00 5.574e+00 1.050e+02\n 6.248e-03 3.374e-02 5.196e-02 1.158e-02 2.007e-02 4.560e-03 2.315e+01\n 3.401e+01 1.605e+02 1.670e+03 1.491e-01 4.257e-01 6.133e-01 1.848e-01\n 3.444e-01 9.782e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}